# backend/agent.py

from abc import ABC, abstractmethod
from typing import List
from backend.entity import Note
from backend.interfaces import StorageInterface
from backend.prompt_loader import PromptLoader
from utils import LLM

class RetrieverInterface(ABC):
    @abstractmethod
    def retrieve(self, query: str, router_prompt_template: str, limit: int = 10) -> List[Note]:
        pass

class TagRouteRetriever(RetrieverInterface):
    def __init__(self, storage: StorageInterface, llm: LLM):
        self.storage = storage
        self.llm = llm

    def retrieve(self, query: str, router_prompt_template: str, limit: int = 20) -> List[Note]:
        if not self.llm: return []
        all_tags = self.storage.get_all_tags()
        if not all_tags: return []

        selected_tags = self._ask_llm_to_pick_tags(query, all_tags, router_prompt_template)
        if selected_tags: print(f"ğŸ¤– [Agent] Router selected: {selected_tags}")

        candidates = []
        seen_ids = set()
        for tag in selected_tags:
            tag_notes = self.storage.load(tag)
            for note in tag_notes:
                if note.id not in seen_ids:
                    candidates.append(note)
                    seen_ids.add(note.id)
        candidates.sort(key=lambda x: x.created_at, reverse=True)
        return candidates[:limit]

    def _ask_llm_to_pick_tags(self, query: str, all_tags: List[str], template: str) -> List[str]:
        tags_str = ", ".join(all_tags)
        prompt = template.replace("{all_tags}", f"[{tags_str}]").replace("{query}", query)
        response = self.llm.chat(prompt, use_history=False)
        if not response or "None" in response: return []
        picked = [t.strip() for t in response.split(',')]
        valid_tags = [t for t in picked if t in all_tags]
        return valid_tags

class KnowledgeAgent:
    def __init__(self, storage: StorageInterface, llm: LLM, prompts_dir: str):
        self.storage = storage
        self.llm = llm
        self.loader = PromptLoader(prompts_dir)
        self.retriever: RetrieverInterface = TagRouteRetriever(storage, llm)

    def _load_prompt(self, name: str, default: str) -> str:
        prompts = self.loader.load_prompts()
        return prompts.get(name, default)

    def clear_history(self):
        if self.llm: self.llm.clear_history()

    def chat(self, user_input: str, use_knowledge: bool = False) -> str:
        if not self.llm: return "âŒ AI æ¨¡å—æœªé…ç½®ã€‚"

        if not use_knowledge:
            print("ğŸ’¬ [Agent] Normal Chat Mode")
            return self.llm.chat(user_input, use_history=True)

        print("ğŸ”Œ [Agent] Knowledge Base Mode")
        router_template = self._load_prompt("rag_router", "{query} {all_tags}")
        summary_template = self._load_prompt("rag_summary", "{context} {query}")

        relevant_notes = self.retriever.retrieve(user_input, router_template)
        
        context_str = ""
        if relevant_notes:
            for i, note in enumerate(relevant_notes):
                clean_content = note.content.replace('\n', ' ')[:500]
                
                # [ä¿®æ”¹] ä½¿ç”¨ filename (çœŸå®æˆ–è™šæ‹Ÿ)
                file_name = note.metadata.get('filename', 'Unknown_File')
                
                # æç¤º LLMï¼šè¿™æ˜¯èµ„æ–™çš„æ¥æºä¿¡æ¯ï¼Œè¯·åœ¨å›ç­”ä¸­å¼•ç”¨
                meta_info = f"æ ‡ç­¾: {note.tags}, æ–‡ä»¶å: {file_name}"
                context_str += f"> [èµ„æ–™{i+1}] ({meta_info})\nå†…å®¹: {clean_content}\n\n"
        else:
            context_str = "ï¼ˆæœ¬æ¬¡æ£€ç´¢æœªå‘ç°åŒ¹é…çš„ç¬”è®°ï¼‰"

        final_prompt = summary_template.replace("{context}", context_str).replace("{query}", user_input)
        return self.llm.chat(final_prompt, use_history=True)